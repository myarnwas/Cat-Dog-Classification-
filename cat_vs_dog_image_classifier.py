# -*- coding: utf-8 -*-
"""cat_vs_dog_image_classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/komalaftab/convolutional-neural-network/blob/master/cat_vs_dog_image_classifier.ipynb

**Cats Vs Dogs image classifier**

**Loading dataset**


You can load the dataset from the [kaggle website.](https://www.kaggle.com/c/dogs-vs-cats/data).
"""

!wget --no-check-certificate \
  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \
  -O /tmp/cats_and_dogs_filtered.zip

"""**Unzip data using python code:**

The following python code will use the OS library, giving you access to the file system, and the zipfile library allowing you to unzip the data.
"""

import os
import zipfile

local_zip = '/tmp/cats_and_dogs_filtered.zip'

zip_ref = zipfile.ZipFile(local_zip, 'r')

zip_ref.extractall('/tmp')
zip_ref.close()

"""**Let's define the directories.**


Dataset containing three subsets: a training set with 1,000 samples of each class, a validation set with 500 samples of each class, and a test set with 500 samples of each class.

![image.png](data:image/png;base64,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)
"""

base_dir = '/tmp/cats_and_dogs_filtered'

train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')


# Directory with our training cat/dog pictures
train_cats_dir = os.path.join(train_dir, 'cats')
train_dogs_dir = os.path.join(train_dir, 'dogs')

# Directory with our validation cat/dog pictures
validation_cats_dir = os.path.join(validation_dir, 'cats')
validation_dogs_dir = os.path.join(validation_dir, 'dogs')

"""Now let's see the filenames look like dogs and cats train directories."""

train_cat_fnames = os.listdir( train_cats_dir )
train_dog_fnames = os.listdir( train_dogs_dir )

print(train_cat_fnames[:10])
print(train_dog_fnames[:10])

"""**Let's find the total no of cats and dogs in train ,validation and test dataset.**"""

print('total training cat images :', len(os.listdir(      train_cats_dir ) ))
print('total training dog images :', len(os.listdir(      train_dogs_dir ) ))

print('total validation cat images :', len(os.listdir( validation_cats_dir ) ))
print('total validation dog images :', len(os.listdir( validation_dogs_dir ) ))

"""**Visualizing data:**"""

import matplotlib.image as mpimg
import matplotlib.pyplot as plt

# Parameters for our graph; we'll output images in a 4x4 configuration
nrows = 4
ncols = 4

pic_index = 0 # Index for iterating over images

"""**Now, display a batch of 8 cat and 8 dog pictures. You can rerun the cell to see a fresh batch each time:**"""

# Set up matplotlib fig, and size it to fit 4x4 pics
fig = plt.gcf()
fig.set_size_inches(ncols*4, nrows*4)

pic_index+=8

next_cat_pix = [os.path.join(train_cats_dir, fname)
                for fname in train_cat_fnames[ pic_index-8:pic_index]
               ]

next_dog_pix = [os.path.join(train_dogs_dir, fname)
                for fname in train_dog_fnames[ pic_index-8:pic_index]
               ]

for i, img_path in enumerate(next_cat_pix+next_dog_pix):
  # Set up subplot; subplot indices start at 1
  sp = plt.subplot(nrows, ncols, i + 1)
  sp.axis('Off') # Don't show axes (or gridlines)

  img = mpimg.imread(img_path)
  plt.imshow(img)

plt.show()

"""**Building a Small Model:**"""

import tensorflow as tf

model = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image 150x150 with 3 bytes color
    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    # 512 neuron hidden layer
    tf.keras.layers.Dense(512, activation='relu'),
    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')
    tf.keras.layers.Dense(1, activation='sigmoid')
])

#The model.summary() method call prints a summary of the NN

model.summary()

"""compile model:

**We train our model with the binary_crossentropy loss, because it's a binary classification problem and our final activation is a sigmoid.We will use the rmsprop optimizer with a learning rate of 0.001. During training, we will want to monitor classification accuracy.
Using the RMSprop optimization algorithm is preferable to stochastic gradient descent (SGD), because RMSprop automates learning-rate tuning for us. (Other optimizers, such as Adam and Adagrad, also automatically adapt the learning rate during training, and would work equally well here.)**
"""

from tensorflow.keras.optimizers import RMSprop

model.compile(optimizer=RMSprop(lr=0.001),
              loss='binary_crossentropy',
              metrics = ['accuracy'])

"""Data preprocessing:

In keras it can be done via thekeras.preprocessing.image.ImageDataGenerator class using the rescale parameter. This ImageDataGenerator class allows you to instantiate generators of augmented image batches (and their labels) via .flow(data, labels) or .flow_from_directory(directory). These generators can then be used with the Keras model methods that accept data generators as inputs: fit, evaluate_generator, and predict_generator.
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# All images will be rescaled by 1./255.
train_datagen = ImageDataGenerator( rescale = 1.0/255.,rotation_range=40,
width_shift_range=0.2,
height_shift_range=0.2,
shear_range=0.2,
zoom_range=0.2,
horizontal_flip=True )
test_datagen  = ImageDataGenerator( rescale = 1.0/255. )

# --------------------
# Flow training images in batches of 20 using train_datagen generator
# --------------------
train_generator = train_datagen.flow_from_directory(train_dir,
                                                    batch_size=32,
                                                    class_mode='binary',
                                                    target_size=(150, 150))
# --------------------
# Flow validation images in batches of 20 using test_datagen generator
# --------------------
validation_generator =  test_datagen.flow_from_directory(validation_dir,
                                                         batch_size=32,
                                                         class_mode  = 'binary',
                                                         target_size = (150, 150))

"""**Training:**

Let's train on all 2,000 images available, for 15 epochs, and validate on all 1,000 test images.
"""

history = model.fit(train_generator,
                              validation_data=validation_generator,
                              steps_per_epoch=100,
                              epochs=20,
                              validation_steps=50,
                              verbose=2)

"""**Evaluating Accuracy and Loss for the Model**:

Let's plot the training/validation accuracy and loss as collected during training:
"""

#-----------------------------------------------------------
# Retrieve a list of list results on training and test data
# sets for each training epoch
#-----------------------------------------------------------
acc      = history.history[     'accuracy' ]
val_acc  = history.history[ 'val_accuracy' ]
loss     = history.history[    'loss' ]
val_loss = history.history['val_loss' ]

epochs   = range(len(acc)) # Get number of epochs

#------------------------------------------------
# Plot training and validation accuracy per epoch
#------------------------------------------------
plt.plot  ( epochs,     acc )
plt.plot  ( epochs, val_acc )
plt.title ('Training and validation accuracy')
plt.figure()

#------------------------------------------------
# Plot training and validation loss per epoch
#------------------------------------------------
plt.plot  ( epochs,     loss )
plt.plot  ( epochs, val_loss )
plt.title ('Training and validation loss'   )

model_2 = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image 150x150 with 3 bytes color
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.Conv2D(32, (3,3),activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3),activation='relu'),
    tf.keras.layers.Conv2D(64, (3,3) ,activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3) ,activation='relu'),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),
    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(512,(3,3),activation='relu'),
    #tf.keras.layers.Conv2D(512,(3,3),activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),



    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    # 256 neuron hidden layer
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dropout((0.4)),




    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')
    tf.keras.layers.Dense(1, activation='sigmoid')
])
model_2.compile(loss='binary_crossentropy',
            optimizer=RMSprop(lr=0.0001),
            metrics=['accuracy'])

history_1= model_2.fit(train_generator,
                              validation_data=validation_generator,
                              steps_per_epoch=100,
                              epochs=50,
                              validation_steps=50,
                              verbose=2)

"""**Deploy model on colab**:


Let's now take a look at actually running a prediction using the model. This code will allow you to choose 1 or more files from your file system, it will then upload them, and run them through the model, giving an indication of whether the object is a dog or a cat.
"""

import numpy as np

from google.colab import files
from keras.preprocessing import image

uploaded=files.upload()

for fn in uploaded.keys():

  # predicting images
  path='/content/' + fn
  img=image.load_img(path, target_size=(150, 150))

  x=image.img_to_array(img)
  x=np.expand_dims(x, axis=0)
  images = np.vstack([x])

  classes = model.predict(images, batch_size=10)

  print(classes[0])

  if classes[0]>0:
    print(fn + " is a dog")

  else:
    print(fn + " is a cat")

"""#how to save model?"""

model.save('cats_and_dogs_small_2.h5')

